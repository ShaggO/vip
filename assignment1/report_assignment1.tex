\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{mathtools}
\usepackage{subcaption}

\usepackage{amsmath,amssymb,amsfonts}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\title{Vision and Image Processing\\Assignment 1}
\author{Malte St√¶r Nissen}

\begin{document}
\maketitle

\section{Detecting interest points}

The detection of interest points can be made by using a variety of methods. I
have implemented\footnote{The entire implementation of this assignment is made
in Matlab 2012b.} both the two blob detectors Difference of Gaussians (DoG) and
Laplacian of Gaussian (LoG) as well as the Harris corner detector. All three detectors
are implemented by hand only using simple Matlab standard functions.

Both blob detectors are implemented by first creating either a DoG or LoG
filter. These filters are created by sampling the appropriate Gaussian
distribution(s) (and their derrivatives) with a support radius of $3\sigma$
and hence a filter size of $\ceil{6 \sigma} \times \ceil{6\sigma}$ in order to
get a sufficient part of the distribution included in the filter. The second
part of the blob detectors is to perform a simple convolution of an image with
the filter just found. The boundary cases are handled by using replication of
boundary pixels to avoid the padding to contribute to the derrivatives.

\begin{figure}
    \begin{subfigure}[t]{0.5\textwidth}
        \includegraphics[width=\textwidth]{}
        \caption{}
        \label{fig:1a}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \includegraphics[width=\textwidth]{}
        \caption{}
        \label{fig:2b}
    \end{subfigure}
    \caption{}
    \label{fig:1}
\end{figure}

\section{Simple matching of features}

\subsection{Normalized Cross Correlation}

The performance decreases since a larger variation in the view angle between
the two images naturally change the lighting and view of the physical objects.
This will in terms change the shapes captured by the camera. Furthermore some
previously captured interest points could be hidden due to the angle change
and new interest points could likewise be revealed. All these changes make it
harder for our matching algorithm as the optimal patch matches decrease in
similarity and hence we are prone to erroneous matching.

\end{document}

